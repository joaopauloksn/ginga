# Ginga: Adaptive Microservices Autoscaling Framework

**Ginga** is an openâ€‘source implementation of the **MSâ€‘DDA architecture** â€” a dataâ€‘driven and adaptive solution for autoscaling microservices in Kubernetes environments. It was developed as part of the masterâ€™s dissertation *â€œAn Adaptive Dataâ€‘Driven Architecture for Microservices Autoscalingâ€* by JoÃ£oÂ PauloÂ KarolÂ SantosÂ NunesÂ (USP,â€¯2025).

> ðŸ§ Â Ginga combines realâ€‘time monitoring, machineâ€‘learning predictions, and infrastructure awareness to scale microservices efficiently â€” reducing cloud costs and improving performance.

---

## ðŸ“ŒÂ Highlights

- âœ…Â Realâ€‘time MLâ€‘based autoscaling (horizontal **and** vertical)
- ðŸ“ŠÂ PrometheusÂ +Â MongoDB metrics backend
- âš™ï¸Â Custom Kubernetes Operator with CRD
- â˜ï¸Â Fully containerised for OpenShift/Kubernetes
- ðŸ§ªÂ Openâ€‘source tool born from academic research

---

## ðŸ“¦Â Architecture

Ginga follows the **MSâ€‘DDA** architecture, whose key building blocks are:

| Component | Purpose |
|-----------|---------|
| **Custom Resource Definition (CRD)** | Declares microserviceâ€‘specific autoscaling parameters |
| **Deployment Operator** | Watches CRDs and triggers the predictâ€‘andâ€‘scale loop |
| **ModelÂ Predictor** | Loads a trained neural network (`.h5`) to predict required replicas |
| **ScalerÂ Service** | Applies replica changes via the Kubernetes API |
| **Monitoring Layer** | Prometheus collects CPU, memory, throughput and latency metrics |
| **Data Store** | MongoDB stores historical metrics for training and inference |

> A detailed diagram is available in `docs/ginga_architecture.png` or FigureÂ 7 of the dissertation.

---

## ðŸš€Â GettingÂ Started

> **Prerequisites:** A Kubernetes/OpenShift cluster with Prometheus **and** MongoDB reachable by the pods.

###Â 1.Â Clone the repository

```bash
git clone https://github.com/joaopauloksn/ginga.git
cd ginga
```

###Â 2.Â Build & push the Docker image (example)

```bash
docker build -t <your-registry>/ginga-predictor:latest -f docker/Dockerfile .
docker push <your-registry>/ginga-predictor:latest
```

###Â 3.Â Deploy Ginga components

```bash
kubectl apply -f k8s/crds/
kubectl apply -f k8s/operator/
```

###Â 4.Â Provide the ML model

Ginga expects a trained model at:

```text
/shared-volume/model.h5
```

Copy your `best_model.h5` there (or mount a volume that contains it).

###Â 5.Â Deploy a sample microservice

```bash
kubectl apply -f samples/iotoccupancy-deployment.yaml
```

---

## ðŸ§ Â Machineâ€‘LearningÂ Model

The bundled neural network is trained on realâ€‘world operational metrics and labelled using serviceâ€‘level objectives (SLOs).

- **Inputs:** CPU, memory, delivered/undelivered messages, latency, etc.  
- **Output:** Optimal number of replicas (e.g.,Â 1,Â 2Â orÂ 3)

To retrain your own model, see the companion repo **msddaâ€‘modelâ€‘development**.

---

## ðŸ“Â ProjectÂ Layout

```
ginga/
â”œâ”€â”€ docker/                 # Dockerfile & requirements
â”œâ”€â”€ k8s/                    # CRDs and operator manifests
â”œâ”€â”€ samples/                # Example workloads
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ task.py
â”‚   â””â”€â”€ model_deployment/
â”‚       â”œâ”€â”€ predict.py
â”‚       â””â”€â”€ scaler.py
â”œâ”€â”€ models/                 # best_model.h5 (not committed)
â””â”€â”€ README.md
```

---

## ðŸ“ŠÂ Evaluation Summary

In an IoT case study, Ginga outperformed Kubernetes HPA:

* **CPUÂ usage:** â†“Â 50â€¯%  
* **MemoryÂ usage:** â†“Â 87â€¯%  
* **Replica count:** â†“Â 90â€¯% (thanks to vertical + horizontal scaling)

See ChapterÂ 4 of the dissertation for full experiment details.

---

## ðŸ“šÂ Citation

> Nunes,Â J.â€¯P.Â K.Â S.Â (2025). *An Adaptive Dataâ€‘Driven Architecture for Microservices Autoscaling*. Masterâ€™s Dissertation â€“ ICMC/USP.

---

## ðŸ“œ License

Licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0).

---

## ðŸ™ŒÂ Acknowledgements

- Instituto de CiÃªncias MatemÃ¡ticas e de ComputaÃ§Ã£o â€“ USP  
- Prof.Â ElisaÂ YumiÂ Nakagawa for supervision and guidance  
